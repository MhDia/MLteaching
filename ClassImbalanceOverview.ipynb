{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Class Imbalance\n",
    "(Author: Mohamad Dia, 1 September 2020)\n",
    "> Note: This is a preliminary document that is supposed to give an overview of the class imbalance problem and suggest some solutions for internal use among course instructors. A more pedagogical version with code snippets or an extended blog post can be built on it later on for external use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Why class imbalance is a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training an ML algorithm with imbalanced dataset might **create a learning bias** against the minority class(es) and consequently **affect the predictive performance** on such class(es). This is because most of the ML algorithms inherently assume balanced dataset and equal costs of errors (i.e. the cost of a false alarm is the same as the cost of a miss). Furthermore, the **performance evaluation under class-imbalance becomes more challenging**, especially when different errors are perceived with different degrees of importance (e.g. in medical applications the cost of a miss is much higher than that of a false alarm while diagnosing a fatal disease, and such costs can not be always quantified). In this case standard metrics such as accuracy, and sometimes the area under the ROC curve (AUROC), become less informative and even misleading in some high imbalance situations. Therefore, it is very essential to understand the effects of class imbalance on learning algorithms and examine how one can mitigate such effects and perform informative evaluations. We will start first by investigating the problems arising with the class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 Prior bias (in the case of prior distribution drift between training and testing): <a name=\"A1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a problem arising in special circumstances where the class imbalance is not expected to be the same during training and testing. For instance, assume we are running a binary classification on cats and dogs images. For some reason, during the data collection, we were able to build a training dataset with 80% cats and 20% dogs. However, during testing we are expecting that our classifier will be tested on a more balanced situation where 50% of the images belong to cats and 50% belong to dogs. In such case, and assuming our classifier has *enough learning capacity*, the algorithm will inherently learn the wrong priors and lead to biased predictions at the test time.\n",
    "\n",
    "Formally, let $x$ be the input, e.g. a cat/dog image, of a binary classifier $f(\\cdot)$. You can think of $f(\\cdot)$ being a logistic regression or a neural network mapping $x$ to $f(x)$. In such case, $f(x)$ represents the posterior probability of $x$ being in class $C1$, say cats, where \n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = p(C1/x) \\propto p(x/C_1) \\times p(C1).\n",
    "\\end{equation}\n",
    "\n",
    "The prediction is then made by choosing the class with higher posterior (if $f(x)>1/2$, which means $p(C1/x) > p(C2/x)$,  then it is a cat, otherwise dog).\n",
    "\n",
    "> <sub>\n",
    "In the case of logistic regression, one can easily link the posterior probability to the parameters ($w$ and $b$)\n",
    "\\begin{align}\n",
    "p(C_1|x) = \\frac{p(x|C_1)p(C_1)}{p(x)} = \\frac{p(x|C_1)p(C_1)}{p(x|C_1)p(C_1) + p(x|C_2)p(C_2)}= \\frac{1}{1 + \\frac{p(x|C_2)p(C_2)}{p(x|C_1)p(C_1)}}\n",
    "= \\frac{1}{1 + \\exp\\left(-\\ln\\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}\\right)} = \\frac{1}{1 + \\exp\\left(-(w^Tx + b)\\right)} = \\sigma(w^Tx + b).\n",
    "\\end{align}\n",
    " </sub>\n",
    "\n",
    "Assuming that the classifier has enough capacity, it will learn the *biased* training prior $p(C1)=0.8$. If we expect that such prior distribution does not hold during test time, we need to mitigate this problem. This can be done during training time (re-balance dataset via sampling/data augmentation, use penalized models) or at the test time (correct the output probability, adjust threshold) as we will see later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 Poor predictive performance on the minority class: <a name=\"A2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a more general problem that holds even if the imbalance persists during the test time. Take for example the prediction of a fatal rare disease: the dataset is expected to be imbalanced both during training and testing, and there is no issue of distribution drift here. However, the imbalance can still affect the learning task. This is because the relatively few instances in the minority class are not enough for the algorithm to fully discover the feature space and learn the appropriate rule. Therefore, the problem here is not in learning a biased prior as in the previous section, but rather in the ability to learn the whole posterior probability.\n",
    "\n",
    "Take the Gaussian naive Bayes classifier as an example. In case of few instance in one of the classes, we will get a poor estimation for both the prior and the Gaussian likelihood, and hence a poor performance (high generalization error).\n",
    "\n",
    "> Note that in the previous section we had assumed that the learning algorithm has *enough learning capacity* in order to filter out this effect and focus on the prior's bias.\n",
    "\n",
    "In order to mitigate such problem, one has to adjust the data or the model during training (data augmentation, penalized models). However, re-balancing the data or penalizing the machine learning model can create an *artificial bias* that needs to be corrected during test time. More information on this in the sequel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3 Less informative evaluation metrics: <a name=\"A3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy metric is meaningful for a relatively balanced dataset and for the cases where the two types of errors have the same cost (cost of false alarm = cost of miss). However, for imbalanced datasets the accuracy metrics can become misleading by giving an inflated measure that can be easily beaten by a dummy classifier. Similarly for other evaluation metrics such as the false positive rate (FPR) used in the ROC.\n",
    "\n",
    "Lets first review different evaluation metrics in a binary classification set up:\n",
    "- Accuracy $= (TP + TN)/(P+N) = (TP + TN)/(TP + FN + TN + FP)$\n",
    "- TPR or recall $= TP/P = TP/(TP+FN)$\n",
    "- FPR = $FP/N = FP/(FN+TN)$\n",
    "- precision $= TP/(TP+FP)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the imbalance dataset is that the majority class (usually the negative class) is overwhelming. Hence, with any reasonable classifier the $TN$ term will dominate the numerator and denominator in the accuracy and makes it close to $1$. Similarly for the false positive rate (FPR) where the dominating $TN$ term makes it always close to zero. Therefore, the accuracy and the ROC might be misleading in assessing the performance under class imbalance.\n",
    "\n",
    "Ideally, we want both the $FN$ and $FP$ terms to be small without including the dominating $TN$ term. Hence, **it is a good practice to look at the precision and recall** which are not sensitive to the class imbalance through the $TN$ term. One way to combine these two metrics is via a harmonic mean F-1 score. This is of course under the assumptions that both types of error have the same cost. If not, one can use a weighted version of such score, e.g. F-$\\beta$ score. In general, it is always recommended to look at the entire confusion matrix in such cases.\n",
    "\n",
    "More info on F-1 score with useful visualizations [here](https://github.com/MhDia/MLteaching/blob/master/T2_F1score.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** The precision and recall, and hence the F-1 score, are less sensitive to class imbalance under the convention that the majority class in the negative class (i.e. the $TN$ term is relatively large than the $TP$ term). In case of a flip of convention, the precision and recall might become misleading and one needs to look at their counterpart that excludes the $TP$ terms. Therefore, it is better to stick with the convention for class imbalance (majority class being the negative class labeled by $0$ for binary classification in `sklearn`).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. How to mitigate the class imbalance problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effects of the class imbalance might vary based on the degree of imbalance, the amount of available data, and the type of the ML model and learning algorithm used. In some cases, one might get satisfactory performance results via standard hyper-parameter tuning and without considering further modifications in the training pipeline. However, in many other cases, especially under high imbalance and limited amount of data, one needs to address the class imbalance during the training and/or testing phases. Below are common techniques to mitigate the class imbalance problem. Such techniques can be used separately or in conjunction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1 Re-balance training dataset:<a name=\"B1\"></a>\n",
    "Try to re-balance the training dataset in favor of the minority class via the following techniques: \n",
    "- Collect more data for the minority class (if possible)\n",
    "- Data augmentation of the minority class (creating synthetic samples/features, e.g. [SMOTE](https://arxiv.org/pdf/1106.1813.pdf))\n",
    "- Up-sample the minority class during training\n",
    "- Down-sample the majority class during training\n",
    "\n",
    "> Note that one needs to be careful while re-balancing the training dataset. Overdoing this technique might create an *artificial bias* in the [training prior](#A1) that needs to be corrected during test time (see [B.3](#B3) below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2 Use penalized models for training (cost-sensitive models):<a name=\"B2\"></a>\n",
    "Penalize the minority class more than the majority class by adjusting the cost function. For example, if class A is twice less frequent than class B in the training dataset, define a cost function that penalizes class A more than class B. This way will make the ML model focus more on the minority class in order to compensate for the imbalance. This can be easily done in `sklearn` models by changing the `class_weight` parameter (alternatively, one can change the `sample_weight` in the `fit` method). The `'balanced'` mode in `class_weight` automatically adjusts the cost function by picking weights representing the inverse class frequencies. One can manually choose such weights and tune them during hyper-parameters tuning on the validation set. Penalized models have similar, but not exactly the same effect as the techniques mentioned in [B.1](#B1) above.\n",
    "\n",
    "> Similarly as in [B.1](#B1), one needs to carefully choose the weights in order not to create an *artificial bias* in the training prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3 Adjust the predictions during testing:<a name=\"B3\"></a>\n",
    "This technique is mainly used to correct the prior bias due to drift in distribution (see [A.1](#A1)) or due to artificial bias added during training. The idea is to adjust the output probabilities, or alternatively the decision threshold, at the prediction time in order to account for the bias. Take for example the binary classification problem, an ML model such as logistic regression is trained to output a prediction representing the posterior probability of an input being in class 1 or 0. The decision is then made based on the magnitude of the probabilities. If $p(x/C_1)>p(x/C_0)$ then we decide that x belongs to class 1, otherwise it belongs to class 0. The default threshold used for such binary classification is $\\alpha = 1/2$, i.e. if $p(x/C_1)>\\alpha$ it is believed that $x$ is in class 1. Such threshold is made based on the assumption that the prior distributions don't change between training and testing. However, this assumption might be violated due to a drift in distribution or artificial bias added during training. In this case one needs to modify the threshold $\\alpha$ during testing. If the prior bias is numerically quantified, which is not usually possible, one can then compute the optimal $\\alpha$ and use it at the test time. In practice, such threshold can be tuned empirically during testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.4 Use appropriate evaluation metrics:\n",
    "Using evaluation metrics that are less sensitive to class imbalance and that separately assess each type of errors is very essential when evaluating the final performance. This is because many standard metrics, such as the accuracy, might become less informative and even misleading under class imbalance (as explained in [A.3](#A3) above). Some of the recommended metrics to use under class imbalance:\n",
    "- Precision and recall (precision/recall curve depicts both metrics in one plot).\n",
    "- F-1 score (which is a harmonic average of precision and recall). One can use a weighted version of F-1 score called the F-$\\beta$ score.\n",
    "- Confusion matrix to look at each type of error separately.\n",
    "- Avoid misleading metrics: accuracy, FPR, TNR (a.k.a. specificity/selectivity), or any metric where the $TN$ term is dominate. The ROC and AUROC can become misleading as well for highly imbalanced datasets.\n",
    "\n",
    "Note that choosing appropriate metrics to evaluate the final performance is usually used in conjunction with at least one of the techniques mentioned above to mitigate the class imbalance. Note also that such metrics are useful when different types of errors are perceived with different degrees of importance, even if the dataset is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Python exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will investigate the effect of class imbalance through a real-life example on the [Haberman Breast Cancer](https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.names) dataset. The ML task consists of applying binary classification to predict whether a patient who had undergone a surgery for breast cancer will survive or not after 5-years of operation based on three measured features. The dataset is small (306 total entries) with mild class imbalance ($26$% is the size the minority \"positive\" class, i.e. the patients who died within 5 years). Furthermore, this dataset presents a good use-case where the types of errors have different costs and degrees of importance: mistakenly predicting that a healthy patient will die (i.e. false alarm) is less problematic and costly than mistakenly predicting that a sick patient will survive (i.e. false miss). The first type of error might incur extra useless treatments and medications, while the second type of error might result in death! We will consider two case studies below to investigate the various problems arising with class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the dataset and check the degree of imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and necessary modules from scikit learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.csv', header=None)\n",
    "X = df.values[:, :-1].astype(float)\n",
    "y = df.values[:, -1]\n",
    "y = y-1 #convert labels from 1/2 format to 0/1 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Positive class:  [26.5] %\n",
      " Negative class:  [73.5] %\n"
     ]
    }
   ],
   "source": [
    "# Compute the imbalance\n",
    "pos_freq = np.round([sum(y)/len(y)],3)*100\n",
    "print(\" Positive class: \", (pos_freq), \"%\\n\", \"Negative class: \", (100-pos_freq), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1 First case study (penalized model):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first scenario, we will tackle the general case where there is no drift in prior distributions (i.e. the same degree of imbalance encountered during training is expected to persist during the test time). We will see how such imbalance affects the predictive performance and how to mitigate it via penalized models and the adoption of appropriate evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the data randomly, we can notice that the imbalance occurs during both training and testing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for traing and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive class (train):  [26.3] %\n",
      "Negative class (train):  [73.7] %\n",
      "\n",
      "Positive class (test):  [26.7] %\n",
      "Negative class (test):  [73.3] %\n"
     ]
    }
   ],
   "source": [
    "# Compute the imbalance on the train and test data\n",
    "pos_freq_train = np.round([sum(y_train)/len(y_train)],3)*100\n",
    "pos_freq_test = np.round([sum(y_test)/len(y_test)],3)*100\n",
    "print(\"Positive class (train): \", (pos_freq_train), \"%\\n\" \"Negative class (train): \", (100-pos_freq_train), \"%\\n\")\n",
    "print(\"Positive class (test): \", (pos_freq_test), \"%\\n\" \"Negative class (test): \", (100-pos_freq_test), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train a binary classifier and evaluate its performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a binary classifier (logistic regression)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels and oputput probabilities of the train/test dataset\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_prob = model.predict_proba(X_train)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset comprises 101 samples (74 negatives case and 27 positive cases). We will evaluate the performance by computing all types of events: true positive, true negative, false positive, and false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN =  69 FP =  5 \n",
      "FN =  20 TP =  7\n"
     ]
    }
   ],
   "source": [
    "# Compute the confusion matrix\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "##print(\"confusion matrix: \\n\", conf_mat)\n",
    "# Print the four events\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "print(\"TN = \", tn, \"FP = \", fp, \"\\nFN = \", fn, \"TP = \", tp) #print(\"confusion matrix: \\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy =  0.75 \n",
      " Recall =  0.26 \n",
      " Precision =  0.58 \n",
      " F-1 score =  0.36 \n",
      " AUROC =  0.6\n"
     ]
    }
   ],
   "source": [
    "# Compute various metrics\n",
    "acc = metrics.accuracy_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "precision = metrics.precision_score(y_test, y_test_pred)\n",
    "f1 = metrics.f1_score(y_test, y_test_pred)\n",
    "auroc = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(\" Accuracy = \", np.round(acc,2), \"\\n\", \"Recall = \", np.round(recall,2), \"\\n\", \"Precision = \", np.round(precision,2), \"\\n\",\n",
    "      \"F-1 score = \", np.round(f1,2), \"\\n\", \"AUROC = \", np.round(auroc,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifiucation report\n",
    "#report = classification_report(y_true=y_test, y_pred=y_test_pred)\n",
    "#print(report)\n",
    "\n",
    "# ROC curve\n",
    "#fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_test_prob[:, 1])\n",
    "#plt.plot(fpr, tpr, label='ROC curve')\n",
    "#plt.xlabel('False Positive Rate')\n",
    "#plt.ylabel('True Positive Rate (Recall)')\n",
    "#plt.title('ROC curve')\n",
    "#plt.grid()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice that the classifier tends to make more false miss (20 false negatives) than false alarm (5 false positives) due to the class imbalance against the positive class. This results on a low recall and F-1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now apply a penalized model that gives more weights for the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a binary classifier (logistic regression) with a penalized model\n",
    "model = LogisticRegression(solver='liblinear', class_weight='balanced') # class_weight={0:1,1:2}\n",
    "model.fit(X_train, y_train, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'balanced'` mode in `class_weight` automatically adjusts the cost function by picking weights representing the inverse class frequencies. One can manually choose such weights and tune them during hyper-parameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels and output probabilities of the train/test dataset\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_prob = model.predict_proba(X_train)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN =  59 FP =  15 \n",
      "FN =  15 TP =  12\n"
     ]
    }
   ],
   "source": [
    "# compute the confusion matrix\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "# Print the four events\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "print(\"TN = \", tn, \"FP = \", fp, \"\\nFN = \", fn, \"TP = \", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy =  0.7 \n",
      " Recall =  0.44 \n",
      " Precision =  0.44 \n",
      " F-1 score =  0.44 \n",
      " AUROC =  0.62\n"
     ]
    }
   ],
   "source": [
    "# Compute various metrics\n",
    "acc = metrics.accuracy_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "precision = metrics.precision_score(y_test, y_test_pred)\n",
    "f1 = metrics.f1_score(y_test, y_test_pred)\n",
    "auroc = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(\" Accuracy = \", np.round(acc,2), \"\\n\", \"Recall = \", np.round(recall,2), \"\\n\", \"Precision = \", np.round(precision,2), \"\\n\",\n",
    "      \"F-1 score = \", np.round(f1,2), \"\\n\", \"AUROC = \", np.round(auroc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the accuracy decreases, you can see that the new model makes less false negatives (better recall and also better F-1 score). Depending on the objective of the ML task at hand, one can manually tune the `class_weight` and/or apply other re-balancing techniques to further improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2 Second case study (prior bias):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will investigate here the effect of bias in priors due to drift in distributions. This is the special case where the imbalance during the test time is expected to be different than that of the training time. Of course, a priori one does not have access to the test data, but in many application scenarios one can have a rough estimate on how the class priors are distributed during the test time and whether they are different or not from the priors at the training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proceed, we will purposely split the data in a way that makes a drift in distributions. Note that this an artificial example, however such situation can happen in practice where data collection during the training time does not represent the priors expected at the test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "y_ind = y==1\n",
    "\n",
    "y_train_pos = y[y_ind][:41]\n",
    "X_train_pos = X[y_ind,:][:41]\n",
    "y_train_neg = y[~y_ind][:185]\n",
    "X_train_neg = X[~y_ind,:][:185]\n",
    "\n",
    "y_test_pos = y[y_ind][41:]\n",
    "X_test_pos = X[y_ind,:][41:]\n",
    "y_test_neg = y[~y_ind][185:]\n",
    "X_test_neg = X[~y_ind,:][185:]\n",
    "\n",
    "y_train = np.concatenate((y_train_pos,y_train_neg), axis = 0)\n",
    "X_train = np.concatenate((X_train_pos,X_train_neg), axis = 0)\n",
    "\n",
    "y_test = np.concatenate((y_test_pos,y_test_neg), axis = 0)\n",
    "X_test = np.concatenate((X_test_pos,X_test_neg), axis = 0)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive class (train):  [18.1] %\n",
      "Negative class (train):  [81.9] %\n",
      "\n",
      "Positive class (test):  [50.] %\n",
      "Negative class (test):  [50.] %\n"
     ]
    }
   ],
   "source": [
    "# Compute the imbalance on the train and test data\n",
    "pos_freq_train = np.round([sum(y_train)/len(y_train)],3)*100\n",
    "pos_freq_test = np.round([sum(y_test)/len(y_test)],3)*100\n",
    "print(\"Positive class (train): \", (pos_freq_train), \"%\\n\" \"Negative class (train): \", (100-pos_freq_train), \"%\\n\")\n",
    "print(\"Positive class (test): \", (pos_freq_test), \"%\\n\" \"Negative class (test): \", (100-pos_freq_test), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the drift in distributions. The training data is imbalanced, unlike the test data which is perfectly balanced. We will train a binary classifier and evaluate its performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a binary classifier (logistic regression)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels and oputput probabilities of the train/test dataset\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_prob = model.predict_proba(X_train)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN =  39 FP =  1 \n",
      "FN =  39 TP =  1\n"
     ]
    }
   ],
   "source": [
    "# Compute the confusion matrix\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "# Print the four events\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "print(\"TN = \", tn, \"FP = \", fp, \"\\nFN = \", fn, \"TP = \", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy =  0.5 \n",
      " Recall =  0.02 \n",
      " Precision =  0.5 \n",
      " F-1 score =  0.05 \n",
      " AUROC =  0.5\n"
     ]
    }
   ],
   "source": [
    "# Compute various metrics\n",
    "acc = metrics.accuracy_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "precision = metrics.precision_score(y_test, y_test_pred)\n",
    "f1 = metrics.f1_score(y_test, y_test_pred)\n",
    "auroc = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(\" Accuracy = \", np.round(acc,2), \"\\n\", \"Recall = \", np.round(recall,2), \"\\n\", \"Precision = \", np.round(precision,2), \"\\n\",\n",
    "      \"F-1 score = \", np.round(f1,2), \"\\n\", \"AUROC = \", np.round(auroc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the model is biased to the negative class. Among 80 samples in the test dataset (40 positive and 40 negative), 75 where predicted to be in the negative class. This is because the model was trained on a dataset with different priors, which makes the model favor the negative class. This results in a very low recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To mitigate this problem, we will modify the prediction by adjusting the output probabilities (or equivalently the decision threshold) as explained in [B.3](#B3). Remember that the binary logistic regression outputs two *posterior probabilities* for each data point using the `predict_proba` method: $p(C1/x)$ and $p(C2/x)$. The decision is then made in the `predict` method by comparing the two probabilities. If $p(C2/x) > p(C1/x)$ then the sample is predicted to be in $C2$, otherwise it is in $C1$. Note that in binary classification this is equivalent to check whether the ratio $p(C2/x)/p(C1/x)$ is greater than $\\gamma = 1$ or whether $p(C2/x)$ is greater than $\\alpha = 1/2$. In order to correct the drift in distribution, we need to adjust the threshold $\\gamma$ (or $\\alpha$). This can be empirically tuned during testing. In this special example the prior bias is numerically quantified, hence we are able to compute the optimal $\\gamma$ using Bayes theorem:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{p(C2/x)}{p(C1/x)} = \\frac{p(x/C_2)p(C2)}{p(x/C_1)p(C1)} > \\gamma = 1.\n",
    "\\end{equation}\n",
    "\n",
    "Due to the drift in distributions, the priors during training ($p(C1)$ and $p(C2)$) are different than the testing priors ($p^*(C1)$ and $p^*(C2)$). In our example we have:\n",
    "\n",
    "- $p(C1) = 0.819$ and $p(C2) = 0.181$\n",
    "- $p^*(C1) = 0.5$ and $p^*(C2) = 0.5$\n",
    "\n",
    "Therefore, we can correct this drift by adjusting the threshold. The optimal threshold $\\gamma^*$ is obtained as follows\n",
    "\n",
    "\\begin{equation}\n",
    "\\gamma^* = \\frac{p^*(C1) p(C2)}{p^*(C2) p(C1)}.\n",
    "\\end{equation}\n",
    "\n",
    "This yields $\\gamma^* \\approx 0.22$ in our example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply this technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ratio of posterior probabilities\n",
    "prob_ratio = y_test_prob[:,1]/y_test_prob[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x116afcc18>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(prob_ratio,'*')\n",
    "plt.plot(np.ones(len(prob_ratio)),'r', label='gamma')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that only few samples are above the decision threshold $\\gamma$. We will now correct this threshold and adjust the prediction accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_corr =  (prob_ratio >0.22).astype(int) # 0.22 is the optimal value of the decision threshold in our case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x116c11470>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(prob_ratio,'*')\n",
    "plt.plot(np.ones(len(prob_ratio_corr))*0.22,'r', label='optimal gamma')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN =  29 FP =  11 \n",
      "FN =  15 TP =  25\n"
     ]
    }
   ],
   "source": [
    "# Compute the confusion matrix\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_test_pred_corr)\n",
    "# Print the four events\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "print(\"TN = \", tn, \"FP = \", fp, \"\\nFN = \", fn, \"TP = \", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy =  0.68 \n",
      " Recall =  0.62 \n",
      " Precision =  0.69 \n",
      " F-1 score =  0.66 \n",
      " AUROC =  0.68\n"
     ]
    }
   ],
   "source": [
    "# Compute various metrics\n",
    "acc = metrics.accuracy_score(y_test, y_test_pred_corr)\n",
    "recall = metrics.recall_score(y_test, y_test_pred_corr)\n",
    "precision = metrics.precision_score(y_test, y_test_pred_corr)\n",
    "f1 = metrics.f1_score(y_test, y_test_pred_corr)\n",
    "auroc = metrics.roc_auc_score(y_test, y_test_pred_corr)\n",
    "\n",
    "\n",
    "print(\" Accuracy = \", np.round(acc,2), \"\\n\", \"Recall = \", np.round(recall,2), \"\\n\", \"Precision = \", np.round(precision,2), \"\\n\",\n",
    "      \"F-1 score = \", np.round(f1,2), \"\\n\", \"AUROC = \", np.round(auroc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clearly notice the great improvement in performance after changing the decision threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References and useful links/libraries:\n",
    "- The impact of class imbalance in classification performance metrics based on the binary confusion matrix (paper). https://www.sciencedirect.com/science/article/pii/S0031320319300950\n",
    "- Classification of imbalanced data: a review (paper). https://www.researchgate.net/publication/263913891_Classification_of_imbalanced_data_a_review#read\n",
    "- The Effects of Class Imbalance and Training Data Size on Classifier Learning: An Empirical Study (paper). https://link.springer.com/article/10.1007/s42979-020-0074-0\n",
    "- The Class Imbalance Problem (book chapter). https://link.springer.com/content/pdf/10.1007%2F978-3-319-47194-5_3\n",
    "- The Impact of Class Rebalancing Techniques on the Performance and Interpretation of Defect Prediction Models (paper). https://arxiv.org/pdf/1801.10269.pdf\n",
    "- 8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset (blog post). https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "- Imbalanced-learn library. https://imbalanced-learn.readthedocs.io/en/stable/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
